{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test pipeline on one instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "from pitch_estimator import PitchEstimator\n",
    "from preprocessors import Preprocessor\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"gamelan_music_dataset\")\n",
    "targets_first = data_path / \"first ensemble/orchestra/target\"\n",
    "audio_file_path = targets_first / \"demung/001.wav\"\n",
    "\n",
    "pitch_est = PitchEstimator()\n",
    "pp = Preprocessor()\n",
    "\n",
    "# Display input audio\n",
    "y, sr = librosa.load(audio_file_path, duration=10)\n",
    "print('Input audio:')\n",
    "display(ipd.Audio(y, rate=sr))\n",
    "\n",
    "# Using median filtering to divide harmonic from percussive component\n",
    "spectrogram = pp.compute_spectrogram(y)\n",
    "harmonic, percussive = pp.apply_median_filtering(spectrogram)\n",
    "\n",
    "\n",
    "# Reconstruct harmonic component audio and display it\n",
    "reconstructed_audio_griffinlim = librosa.griffinlim(harmonic)\n",
    "reconstructed_audio_griffinlim_percussive = librosa.griffinlim(percussive)\n",
    "\n",
    "# https://librosa.org/doc/main/generated/librosa.griffinlim.html\n",
    "print('Harmonic component reconstructed with griffin and lim algorithm:')\n",
    "display(ipd.Audio(reconstructed_audio_griffinlim, rate=sr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onsets = librosa.onset.onset_detect(y=reconstructed_audio_griffinlim_percussive, units=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time, frequency, confidence, activation = pitch_est.estimate_crepe(reconstructed_audio_griffinlim, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the interpolated frequencies\n",
    "plt.plot(time, frequency)\n",
    "plt.xlabel('Time') \n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Crepe Frequencies')\n",
    "\n",
    "for t in onsets:\n",
    "    plt.axvline(x=round(t, 2), color='r', linestyle='-', label=f'Time {t}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tones = []\n",
    "for i, onset in enumerate(onsets):\n",
    "    index_a = np.argmax(time > onset)\n",
    "    if i == len(onsets) - 1: index_b = len(time) - 1\n",
    "    else: index_b = np.argmax(time > onsets[i+1])\n",
    "    frequency_range = frequency[index_a:index_b]\n",
    "    tone = np.median(frequency_range)\n",
    "    print(f'Onset {i}-{i+1}: {tone}')\n",
    "    tones.append(tone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_tones = sorted(tones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_and_average_frequencies(frequencies, threshold=10):\n",
    "    grouped_frequencies = []\n",
    "    current_group = [frequencies[0]]\n",
    "    \n",
    "    for i in range(1, len(frequencies)):\n",
    "        if frequencies[i] - frequencies[i-1] <= threshold:\n",
    "            current_group.append(frequencies[i])\n",
    "        else:\n",
    "            grouped_frequencies.append(sum(current_group) / len(current_group))\n",
    "            current_group = [frequencies[i]]\n",
    "    \n",
    "    grouped_frequencies.append(sum(current_group) / len(current_group))\n",
    "    \n",
    "    return grouped_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_averaged_frequencies = group_and_average_frequencies(sorted_tones)\n",
    "print(grouped_averaged_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tuning_vectors():\n",
    "    \"\"\"\n",
    "    Returns 3 gamelan tuning.\n",
    "    Each entry in the vectors represent the interval in cents between consecutive tones starting from ding.\n",
    "    \"\"\"\n",
    "    begbeg = np.array([120, 114, 432, 81, 453])\n",
    "    sedang = np.array([136, 155, 379, 134, 396])\n",
    "    tirus = np.array([197, 180, 347, 104, 372])\n",
    "    return begbeg, sedang, tirus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
